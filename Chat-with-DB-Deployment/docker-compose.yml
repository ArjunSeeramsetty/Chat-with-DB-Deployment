# Chat with DB - Docker Compose Configuration
# Complete deployment with backend, frontend, and optional services

version: '3.8'

services:
  # Backend API Service
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: chat-with-db-backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_PATH=${DATABASE_PATH:-C:/Users/arjun/Desktop/PSPreport/power_data.db}
      - API_HOST=0.0.0.0
      - API_PORT=8000
      - LLM_PROVIDER_TYPE=${LLM_PROVIDER_TYPE:-ollama}
      - LLM_MODEL=${LLM_MODEL:-llama3.2:3b}
      - LLM_BASE_URL=${LLM_BASE_URL:-http://ollama:11434}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      # Mount database directory (adjust path as needed)
      - ${DATABASE_PATH:-C:/Users/arjun/Desktop/PSPreport}:/data:ro
    depends_on:
      - ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Ollama LLM Service (Local LLM)
  ollama:
    image: ollama/ollama:latest
    container_name: chat-with-db-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Frontend Service (Optional - for development)
  frontend:
    image: node:18-alpine
    container_name: chat-with-db-frontend
    working_dir: /app
    ports:
      - "3000:3000"
    volumes:
      - ./agent-ui:/app
      - /app/node_modules
    command: >
      sh -c "npm install && npm start"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
      - CHOKIDAR_USEPOLLING=true
    depends_on:
      - backend
    restart: unless-stopped
    profiles:
      - dev

  # Nginx Reverse Proxy (Production)
  nginx:
    image: nginx:alpine
    container_name: chat-with-db-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./agent-ui/build:/usr/share/nginx/html:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - backend
    restart: unless-stopped
    profiles:
      - prod

  # Redis Cache (Optional - for session management)
  redis:
    image: redis:7-alpine
    container_name: chat-with-db-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    profiles:
      - cache

  # PostgreSQL (Optional - for advanced analytics)
  postgres:
    image: postgres:15-alpine
    container_name: chat-with-db-postgres
    environment:
      - POSTGRES_DB=chat_with_db
      - POSTGRES_USER=chat_user
      - POSTGRES_PASSWORD=chat_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped
    profiles:
      - analytics

volumes:
  ollama_data:
    driver: local
  redis_data:
    driver: local
  postgres_data:
    driver: local

networks:
  default:
    name: chat-with-db-network
